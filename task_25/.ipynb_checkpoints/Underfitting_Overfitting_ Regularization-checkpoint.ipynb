{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                             \"\"\"BWF - Usama Mahtab\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4928cd",
   "metadata": {},
   "source": [
    "# ***Underfitting:***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aea0f4",
   "metadata": {},
   "source": [
    "***\n",
    "Underfitting means:\n",
    "1. model becomes too simple\n",
    "2. doesn't capture the underlying pattern in the data\n",
    "3. performs poorly on both the training and test data\n",
    "\n",
    "This happens when the model is not complex enough to learn the important patterns in the data.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f90b57",
   "metadata": {},
   "source": [
    "***Solutions of Underfitting:***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6b613",
   "metadata": {},
   "source": [
    "1. Increase model complexity\n",
    "2. Add more features\n",
    "3. Decrease regularization\n",
    "4. Increase the number of training epochs\n",
    "5. Change the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d7a187",
   "metadata": {},
   "source": [
    "# ***Overfitting:***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6decb4de",
   "metadata": {},
   "source": [
    "***\n",
    "Overfitting means: \n",
    "1. model becomes so much complex \n",
    "2. learns so much details and picks the noise from the data\n",
    "3. performs well on the training data but poorly on the test data\n",
    "4. negatively effects the performance for new unseen data\n",
    "\n",
    "This happens because the model has memorized the training data instead of learning the underlying patterns that generalize well.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58c3c6a",
   "metadata": {},
   "source": [
    "***Solutions of Overfitting:***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81584358",
   "metadata": {},
   "source": [
    "***\n",
    "1. get more training data, which can help the model generalize better.\n",
    "\n",
    "2. regularization\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94fb1e",
   "metadata": {},
   "source": [
    "## ***Regularization:***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d822710a",
   "metadata": {},
   "source": [
    "***\n",
    "A common way to mitigate overfitting is to put constraints on the complexity of a network by forcing its weights to take only small values, which makes the distribution of weight values more regular. This is called weight regularization, and it’s\n",
    "done by adding to the loss function of the network a cost associated with having large weights.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70bff6e",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "This cost comes in two flavors:\n",
    "\n",
    "1. L1 regularization—The cost added is proportional to the absolute value of the weight coefficients (the L1 norm of the weights).\n",
    "2. L2 regularization—The cost added is proportional to the square of the value of the weight coefficients (the L2 norm of the weights). L2 regularization is also called weight decay in the context of neural networks. Don’t let the different name confuse you: weight decay is mathematically the same as L2 regularization\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f6471",
   "metadata": {},
   "source": [
    "***Implementing L2-Regularization in Keras:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45993e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4328c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
